{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56520461",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df=pd.read_csv(\"../input/framingham.csv\")\n",
    "heart_df.drop(['education'],axis=1,inplace=True)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in heart_df.isnull().sum(axis=1):\n",
    "    if i>0:\n",
    "        count=count+1\n",
    "print('Total number of rows with missing values is ', count)\n",
    "print('since it is only',round((count/len(heart_df.index))*100), 'percent of the entire dataset the rows with missing values are excluded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef728352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histograms(dataframe, features, rows, cols):\n",
    "    fig=plt.figure(figsize=(20,20))\n",
    "    for i, feature in enumerate(features):\n",
    "        ax=fig.add_subplot(rows,cols,i+1)\n",
    "        dataframe[feature].hist(bins=20,ax=ax,facecolor='midnightblue')\n",
    "        ax.set_title(feature+\" Distribution\",color='DarkRed')\n",
    "        \n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "draw_histograms(heart_df,heart_df.columns,6,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.TenYearCHD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.pairplot(data=heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant as add_constant\n",
    "heart_df_constant = add_constant(heart_df)\n",
    "heart_df_constant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_feature_elem (data_frame,dep_var,col_list):\n",
    "    \"\"\" Takes in the dataframe, the dependent variable and a list of column names, runs the regression repeatedly eleminating feature with the highest\n",
    "    P-value above alpha one at a time and returns the regression summary with all p-values below alpha\"\"\"\n",
    "\n",
    "    while len(col_list)>0 :\n",
    "        model=sm.Logit(dep_var,data_frame[col_list])\n",
    "        result=model.fit(disp=0)\n",
    "        largest_pvalue=round(result.pvalues,3).nlargest(1)\n",
    "        if largest_pvalue[0]<(0.05):\n",
    "            return result\n",
    "            break\n",
    "        else:\n",
    "            col_list=col_list.drop(largest_pvalue.index)\n",
    "\n",
    "result=back_feature_elem(heart_df_constant,heart_df.TenYearCHD,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.exp(result.params)\n",
    "conf = np.exp(result.conf_int())\n",
    "conf['OR'] = params\n",
    "pvalue=round(result.pvalues,3)\n",
    "conf['pvalue']=pvalue\n",
    "conf.columns = ['CI 95%(2.5%)', 'CI 95%(97.5%)', 'Odds Ratio','pvalue']\n",
    "print ((conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "new_features=heart_df[['age','Sex_male','cigsPerDay','totChol','sysBP','glucose','TenYearCHD']]\n",
    "x=new_features.iloc[:,:-1]\n",
    "y=new_features.iloc[:,-1]\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a65122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f87949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sn.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN=cm[0,0]\n",
    "TP=cm[1,1]\n",
    "FN=cm[1,0]\n",
    "FP=cm[0,1]\n",
    "sensitivity=TP/float(TP+FN)\n",
    "specificity=TN/float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The acuuracy of the model = TP+TN/(TP+TN+FP+FN) = ',(TP+TN)/float(TP+TN+FP+FN),'\\n',\n",
    "\n",
    "'The Missclassification = 1-Accuracy = ',1-((TP+TN)/float(TP+TN+FP+FN)),'\\n',\n",
    "\n",
    "'Sensitivity or True Positive Rate = TP/(TP+FN) = ',TP/float(TP+FN),'\\n',\n",
    "\n",
    "'Specificity or True Negative Rate = TN/(TN+FP) = ',TN/float(TN+FP),'\\n',\n",
    "\n",
    "'Positive Predictive value = TP/(TP+FP) = ',TP/float(TP+FP),'\\n',\n",
    "\n",
    "'Negative predictive Value = TN/(TN+FN) = ',TN/float(TN+FN),'\\n',\n",
    "\n",
    "'Positive Likelihood Ratio = Sensitivity/(1-Specificity) = ',sensitivity/(1-specificity),'\\n',\n",
    "\n",
    "'Negative likelihood Ratio = (1-Sensitivity)/Specificity = ',(1-sensitivity)/specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob=logreg.predict_proba(x_test)[:,:]\n",
    "y_pred_prob_df=pd.DataFrame(data=y_pred_prob, columns=['Prob of no heart disease (0)','Prob of Heart Disease (1)'])\n",
    "y_pred_prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369350ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "for i in range(1,5):\n",
    "    cm2=0\n",
    "    y_pred_prob_yes=logreg.predict_proba(x_test)\n",
    "    y_pred2=binarize(y_pred_prob_yes,i/10)[:,1]\n",
    "    cm2=confusion_matrix(y_test,y_pred2)\n",
    "    print ('With',i/10,'threshold the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_yes[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for Heart disease classifier')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y_test,y_pred_prob_yes[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
